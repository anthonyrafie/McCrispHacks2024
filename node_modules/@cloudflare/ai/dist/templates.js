export var templateFlags;
(function (templateFlags) {
    templateFlags[templateFlags["NONE"] = 0] = "NONE";
    templateFlags[templateFlags["CARRY_SYSTEM_INST"] = 1] = "CARRY_SYSTEM_INST";
    templateFlags[templateFlags["ABSORB_ROLE"] = 2] = "ABSORB_ROLE";
    templateFlags[templateFlags["APPEND_LAST_SYSTEM"] = 3] = "APPEND_LAST_SYSTEM";
})(templateFlags || (templateFlags = {}));
export const tgTemplates = {
    bare: {
        system: {
            flag: templateFlags.ABSORB_ROLE,
        },
        user: {
            flag: templateFlags.APPEND_LAST_SYSTEM,
        },
        assistant: {
            pre: " ",
            post: " ",
        },
    },
    inst: {
        system: {
            flag: templateFlags.ABSORB_ROLE,
        },
        user: {
            pre: "[INST] ",
            post: " [/INST]",
            flag: templateFlags.APPEND_LAST_SYSTEM,
        },
        assistant: {
            pre: " ",
            post: " ",
        },
    },
    llama2: {
        system: {
            pre: "[INST] <<SYS>>\n",
            post: "\n<</SYS>>\n\n",
        },
        user: {
            pre: "<s>[INST] ",
            post: " [/INST]",
            flag: templateFlags.CARRY_SYSTEM_INST,
        },
        assistant: {
            pre: " ",
            post: "</s>",
        },
    },
    deepseek: {
        system: {
            post: "\n",
        },
        user: {
            pre: "### Instruction:\n",
            post: "\n",
        },
        assistant: {
            pre: "### Response:\n",
            post: "\n",
        },
        global: {
            post: "### Response:\n",
        },
    },
    openchat: {
        system: {
            flag: templateFlags.ABSORB_ROLE,
        },
        user: {
            pre: "GPT4 User: ",
            post: "<|end_of_turn|>",
            flag: templateFlags.APPEND_LAST_SYSTEM,
        },
        assistant: {
            pre: "GPT4 Assistant: ",
            post: "<|end_of_turn|>",
        },
        global: {
            post: "GPT4 Assistant:",
        },
    },
    chatml: {
        system: {
            pre: "<|im_start|>system\n",
            post: "<|im_end|>\n",
        },
        user: {
            pre: "<|im_start|>user\n",
            post: "<|im_end|>\n",
        },
        assistant: {
            pre: "<|im_start|>assistant\n",
            post: "<|im_end|>\n",
        },
        global: {
            post: "<|im_start|>assistant\n",
        },
    },
    "orca-hashes": {
        system: {
            pre: "### System:\n",
            post: "\n\n",
        },
        user: {
            pre: "### User:\n",
            post: "\n\n",
        },
        assistant: {
            pre: "### Assistant:\n",
            post: "\n\n",
        },
        global: {
            post: "### Assistant:\n\n",
        },
    },
    "codellama-instruct": {
        system: {
            pre: "[INST] ",
            post: "\n",
        },
        user: {
            pre: "[INST] ",
            post: " [/INST]\n",
            flag: templateFlags.CARRY_SYSTEM_INST,
        },
        assistant: {
            post: "\n",
        },
    },
    "mistral-instruct": {
        system: {
            pre: "<s>[INST] ",
            post: " ",
        },
        user: {
            pre: "[INST] ",
            post: " [/INST]",
            flag: templateFlags.CARRY_SYSTEM_INST,
        },
        assistant: {
            pre: " ",
            post: "</s>",
        },
    },
    zephyr: {
        system: {
            pre: "<s><|system|>\n",
            post: "</s>\n",
        },
        user: {
            pre: "<|user|>\n",
            post: "</s>\n",
        },
        assistant: {
            pre: "<|assistant|>\n",
            post: "</s>\n",
        },
        global: {
            post: "<|assistant|>\n",
        },
    },
};
export const generateTgTemplate = (messages, template) => {
    let prompt = "";
    const state = { lastSystem: false, systemCount: 0, userCount: 0, assistantCount: 0 };
    for (const message of messages) {
        switch (message.role) {
            case "system":
                state.systemCount++;
                state.lastSystem = message.content;
                prompt += applyRole(template, message.role, message.content, state);
                break;
            case "user":
                state.userCount++;
                prompt += applyRole(template, message.role, message.content, state);
                break;
            case "assistant":
                state.assistantCount++;
                prompt += applyRole(template, message.role, message.content, state);
                break;
        }
    }
    prompt = applyRole(template, "global", prompt, state);
    return prompt;
};
export const applyTag = (template, role, type, state) => {
    if (type == "pre" &&
        tgTemplates[template][role].flag == templateFlags.CARRY_SYSTEM_INST &&
        state.systemCount == 1 &&
        state.userCount == 1) {
        return "";
    }
    return tgTemplates[template][role][type] || "";
};
export const applyRole = (template, role, content, state) => {
    if (tgTemplates[template] && tgTemplates[template][role]) {
        if (tgTemplates[template][role].flag == templateFlags.ABSORB_ROLE)
            return "";
        if (tgTemplates[template][role].flag == templateFlags.APPEND_LAST_SYSTEM &&
            state.lastSystem &&
            state.userCount == 1) {
            content = `${state.lastSystem}${[":", ".", "!", "?"].indexOf(state.lastSystem.slice(-1)) == -1 ? ":" : ""} ${content}`;
        }
        return applyTag(template, role, "pre", state) + (content || "") + applyTag(template, role, "post", state);
    }
    return content || "";
};
