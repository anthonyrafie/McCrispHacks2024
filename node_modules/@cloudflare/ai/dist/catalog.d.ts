import { AiTextGeneration } from "./tasks/text-generation";
import { AiTextClassification } from "./tasks/text-classification";
import { AiTextEmbeddings } from "./tasks/text-embeddings";
import { AiTranslation } from "./tasks/translation";
import { AiSpeechRecognition } from "./tasks/speech-recognition";
import { AiImageClassification } from "./tasks/image-classification";
import { AiObjectDetection } from "./tasks/object-detection";
import { AiTextToImage } from "./tasks/text-to-image";
import { AiSentenceSimilarity } from "./tasks/sentence-similarity";
export declare const modelMappings: {
    readonly "text-classification": {
        readonly models: readonly ["@cf/huggingface/distilbert-sst-2-int8"];
        readonly class: typeof AiTextClassification;
        readonly id: "19606750-23ed-4371-aab2-c20349b53a60";
    };
    readonly "text-to-image": {
        readonly models: readonly ["@cf/stabilityai/stable-diffusion-xl-base-1.0"];
        readonly class: typeof AiTextToImage;
        readonly id: "3d6e1f35-341b-4915-a6c8-9a7142a9033a";
    };
    readonly "sentence-similarity": {
        readonly models: readonly ["@hf/sentence-transformers/all-minilm-l6-v2"];
        readonly class: typeof AiSentenceSimilarity;
        readonly id: "69bf4e84-441e-401a-bdfc-256fd54d0fff";
    };
    readonly "text-embeddings": {
        readonly models: readonly ["@cf/baai/bge-small-en-v1.5", "@cf/baai/bge-base-en-v1.5", "@cf/baai/bge-large-en-v1.5", "@hf/baai/bge-base-en-v1.5"];
        readonly class: typeof AiTextEmbeddings;
        readonly id: "0137cdcf-162a-4108-94f2-1ca59e8c65ee";
    };
    readonly "speech-recognition": {
        readonly models: readonly ["@cf/openai/whisper"];
        readonly class: typeof AiSpeechRecognition;
        readonly id: "dfce1c48-2a81-462e-a7fd-de97ce985207";
    };
    readonly "image-classification": {
        readonly models: readonly ["@cf/microsoft/resnet-50"];
        readonly class: typeof AiImageClassification;
        readonly id: "00cd182b-bf30-4fc4-8481-84a3ab349657";
    };
    readonly "object-detection": {
        readonly models: readonly ["@cf/facebook/detr-resnet-50"];
        readonly class: typeof AiObjectDetection;
        readonly id: "9c178979-90d9-49d8-9e2c-0f1cf01815d4";
    };
    readonly "text-generation": {
        readonly models: readonly ["@cf/meta/llama-2-7b-chat-int8", "@cf/mistral/mistral-7b-instruct-v0.1", "@cf/meta/llama-2-7b-chat-fp16", "@hf/thebloke/llama-2-13b-chat-awq", "@hf/thebloke/zephyr-7b-beta-awq", "@hf/thebloke/mistral-7b-instruct-v0.1-awq", "@hf/thebloke/codellama-7b-instruct-awq", "@hf/thebloke/openchat_3.5-awq", "@hf/thebloke/openhermes-2.5-mistral-7b-awq", "@hf/thebloke/starling-lm-7b-alpha-awq", "@hf/thebloke/orca-2-13b-awq", "@hf/thebloke/neural-chat-7b-v3-1-awq", "@hf/thebloke/llamaguard-7b-awq", "@hf/thebloke/deepseek-coder-6.7b-base-awq", "@hf/thebloke/deepseek-coder-6.7b-instruct-awq"];
        readonly class: typeof AiTextGeneration;
        readonly id: "c329a1f9-323d-4e91-b2aa-582dd4188d34";
    };
    readonly translation: {
        readonly models: readonly ["@cf/meta/m2m100-1.2b"];
        readonly class: typeof AiTranslation;
        readonly id: "f57d07cb-9087-487a-bbbf-bc3e17fecc4b";
    };
};
export declare const modelSettings: {
    "@hf/sentence-transformers/all-minilm-l6-v2": {
        experimental: boolean;
    };
    "@hf/baai/bge-base-en-v1.5": {
        postProcessingFunc: (r: any) => {
            shape: any;
            data: any;
        };
    };
    "@hf/thebloke/deepseek-coder-6.7b-instruct-awq": {
        route: string;
        experimental: boolean;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (r: any) => any;
        postProcessingFuncStream: (r: any) => any;
    };
    "@hf/thebloke/deepseek-coder-6.7b-base-awq": {
        route: string;
        experimental: boolean;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (response: any, ignoreTokens?: any) => any;
        postProcessingFuncStream: (response: any, ignoreTokens?: any) => any;
    };
    "@hf/thebloke/llamaguard-7b-awq": {
        route: string;
        experimental: boolean;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (response: any, ignoreTokens?: any) => any;
        postProcessingFuncStream: (response: any, ignoreTokens?: any) => any;
    };
    "@hf/thebloke/openchat_3.5-awq": {
        route: string;
        experimental: boolean;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (response: any, ignoreTokens?: any) => any;
        postProcessingFuncStream: (response: any, ignoreTokens?: any) => any;
    };
    "@hf/thebloke/openhermes-2.5-mistral-7b-awq": {
        route: string;
        experimental: boolean;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (r: any) => any;
        postProcessingFuncStream: (r: any) => any;
    };
    "@hf/thebloke/starling-lm-7b-alpha-awq": {
        route: string;
        experimental: boolean;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (r: any) => any;
        postProcessingFuncStream: (r: any) => any;
    };
    "@hf/thebloke/orca-2-13b-awq": {
        route: string;
        experimental: boolean;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (response: any, ignoreTokens?: any) => any;
        postProcessingFuncStream: (response: any, ignoreTokens?: any) => any;
    };
    "@hf/thebloke/neural-chat-7b-v3-1-awq": {
        route: string;
        experimental: boolean;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (response: any, ignoreTokens?: any) => any;
        postProcessingFuncStream: (response: any, ignoreTokens?: any) => any;
    };
    "@cf/stabilityai/stable-diffusion-xl-base-1.0": {
        route: string;
    };
    "@hf/thebloke/llama-2-13b-chat-awq": {
        route: string;
        experimental: boolean;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (response: any, ignoreTokens?: any) => any;
        postProcessingFuncStream: (response: any, ignoreTokens?: any) => any;
    };
    "@hf/thebloke/zephyr-7b-beta-awq": {
        route: string;
        experimental: boolean;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (response: any, ignoreTokens?: any) => any;
        postProcessingFuncStream: (response: any, ignoreTokens?: any) => any;
    };
    "@hf/thebloke/mistral-7b-instruct-v0.1-awq": {
        route: string;
        experimental: boolean;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (response: any, ignoreTokens?: any) => any;
        postProcessingFuncStream: (response: any, ignoreTokens?: any) => any;
    };
    "@hf/thebloke/codellama-7b-instruct-awq": {
        route: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
        postProcessingFunc: (response: any, ignoreTokens?: any) => any;
        postProcessingFuncStream: (response: any, ignoreTokens?: any) => any;
    };
    "@cf/meta/llama-2-7b-chat-fp16": {
        route: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
    };
    "@cf/meta/llama-2-7b-chat-int8": {
        route: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
    };
    "@cf/openai/whisper": {
        experimental: boolean;
        postProcessingFunc: (response: any) => {
            text: any;
            word_count: number;
            words: any;
        } | {
            text: any;
            word_count?: undefined;
            words?: undefined;
        };
    };
    "@cf/mistral/mistral-7b-instruct-v0.1": {
        route: string;
        inputsDefaultsStream: {
            max_tokens: number;
        };
        inputsDefaults: {
            max_tokens: number;
        };
        preProcessingArgs: {
            promptTemplate: string;
            defaultContext: string;
        };
    };
};
export declare const addModel: (task: string, model: string, settings: any) => void;
//# sourceMappingURL=catalog.d.ts.map