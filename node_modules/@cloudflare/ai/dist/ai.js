import { InferenceSession } from "./session";
import { readStream, validateInput, getModelSettings, debugLog } from "./tools";
import { modelMappings, addModel } from "./catalog";
export class Ai {
    constructor(binding, options = {}) {
        this.binding = binding;
        this.options = options;
    }
    addModel(task, model, settings) {
        addModel(task, model, settings);
    }
    async run(model, inputs) {
        const tasks = Object.keys(modelMappings);
        for (var t in tasks) {
            if (modelMappings[tasks[t]].models.indexOf(model) !== -1) {
                const settings = getModelSettings(model);
                const sessionOptions = this.options.sessionOptions || {};
                this.task = new modelMappings[tasks[t]].class(inputs, settings);
                validateInput(tasks[t], inputs);
                debugLog(this.options.debug, "input", inputs);
                if (this.options.apiGateway) {
                    const fetchOptions = {
                        method: "POST",
                        body: JSON.stringify(inputs),
                        headers: {
                            authorization: `Bearer ${this.options.apiToken}`,
                            "content-type": "application/json",
                        },
                    };
                    const res = await fetch(`https://api.cloudflare.com/client/v4/accounts/${this.options.apiAccount}/ai/run/${model}`, fetchOptions);
                    if (!res.ok) {
                        throw new Error(await res.text());
                    }
                    if (res.headers.get("content-type") == "application/json") {
                        const { result } = await res.json();
                        return result;
                    }
                    else if (res.headers.get("content-type") == "text/event-stream") {
                        return readStream(res.body, this.options.debug, sessionOptions.ctx, false, false);
                    }
                    else {
                        const blob = await res.blob();
                        return blob;
                    }
                }
                else {
                    this.task.preProcessing();
                    debugLog(this.options.debug, "pre-processed inputs", this.task.preProcessedInputs);
                    this.task.generateTensors();
                    debugLog(this.options.debug, "input tensors", this.task.tensors);
                    const session = new InferenceSession(this.binding, model, {
                        ...{ debug: this.options.debug ? true : false },
                        ...sessionOptions,
                    });
                    if (inputs.stream) {
                        debugLog(this.options.debug, "streaming", false);
                        return await session.run(this.task.tensors, {
                            stream: true,
                            postProcessing: (r) => {
                                return this.task.postProcessingStream(r);
                            },
                        });
                    }
                    else {
                        const response = await session.run(this.task.tensors);
                        debugLog(this.options.debug, "response", response);
                        this.task.postProcessing(response, sessionOptions.ctx);
                        debugLog(this.options.debug, "post-processed response", this.task.postProcessedOutputs);
                        return this.task.postProcessedOutputs;
                    }
                }
            }
        }
        throw new Error(`No such model ${model} or task`);
    }
}
